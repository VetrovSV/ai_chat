{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добавление контекста в промпт большой языковой модели, для реализации чат-бота"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задачу использования в чат боте языковой моделью контекста (новых данных) без дообучения можно решить так:\n",
    "1. Собрать датасет новых текстовых данных. Разбить его на части. Например на абзацы. Для каждого абзаца создать с помощью простой языковой модели (например BERT, LABSE) векторные представления.\n",
    "2. Вычислить векторное представление текстового запроса пользователя той же моделью. Отобрать топ K похожих текстов сравнивая вектор запроса пользователя с векторами известных абзацев. Это будет контекстом запроса.\n",
    "3. Составит промпт из К отобранных абзацев датасета и запроса пользователя. Отправить промпт в языковую модель обученную быть чатом, например LLama3.\n",
    "\n",
    "Отбор похожих текстов нужен для того, чтобы уместить контекст в промпт языковой модели чат-бота (например LLama3). Т.к. обычно датасет дополнительной информации большой и весь не войдёт в промпт.\n",
    "\n",
    "Это называется Retrieval-Augmented Generation (RAG) или Context Application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примерная схема решения:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://habrastorage.org/r/w1560/getpro/habr/upload_files/a65/c81/973/a65c8197331c24fea7b7b4a5a0985795.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запуск сервера с моделью**\n",
    "\n",
    "Коротко о OLLAMA: https://github.com/ivtipm/ML/blob/main/tools.md\n",
    "\n",
    "\n",
    "1. Скачать OLLAMA\n",
    "2. Скачать языковую модель (чат-бот), например gemma:7b\n",
    "```bash\n",
    "ollama pull gemma:7b\n",
    "```\n",
    "3. Запустить сервер OLLAMA\n",
    "```bash\n",
    "ollama serve\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# установка зависимостей\n",
    "\n",
    "# deprecated: !pip install sentence-transformers langchain-community langchain  faiss-cpu faiss-gpu ollama\n",
    "pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LangChain**\n",
    "\n",
    "Это пакет для взаимодействия с языковыми моделями разного рода (чат-боты, модели для генерации текста, модели выдающие эмбеддинги и т.п.).\n",
    "\n",
    "Предоставляет высокоуровневые типы данных и функции для вышеописанных задач.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.document_loaders import DataFrameLoader                  # отдельный тип для хранения датафреймов\n",
    "# будет разбивать тексты на части, чтобы делать их них эмбеддинги\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка датасета, из которого будет использоваться информация для дополнения промпта\n",
    "\n",
    "def load_dataset( filename:str ):\n",
    "    \"\"\"Загружает датасет из вопросов и ответов.\n",
    "    Формат файла:\n",
    "    Вопрос? <одна строка>\n",
    "    Ответ,\n",
    "    ответ может занимает несколько абзацев или строк\n",
    "    @return: DataFrame(columns=['Q', 'A'])\"\"\"\n",
    "\n",
    "    Q = []      # вопросы\n",
    "    A = []      # ответы\n",
    "\n",
    "    # загрузка вопросов и ответов из файла\n",
    "    for line in open( filename ).readlines():\n",
    "        line = line.strip()\n",
    "        if line.endswith(\"?\"):              # строка - это вопрос\n",
    "            Q += [line]\n",
    "            if len(A) > 0:\n",
    "                A[-1] = A[-1].strip()\n",
    "            A += [\"\"]\n",
    "        else:                               # строка - это ответ или его часть\n",
    "            if len(A) > 0:\n",
    "                A[-1] = A[-1] + \" \" + line\n",
    "            else:\n",
    "                A+= [line]\n",
    "\n",
    "    data = pd.DataFrame( {\"Q\":Q, \"A\":A})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Как мне принять участие/подать заявку на участ...</td>\n",
       "      <td>1. На сайте проекта https://hacks-ai.ru/ в тай...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Я принимал участие в Конкурсе в 2021, 2022 и/и...</td>\n",
       "      <td>Для того чтобы принять участие в хакатоне ново...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Как я узнаю, что моя команда допущена к участи...</td>\n",
       "      <td>Участники команд получат письмо с подтверждени...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Я выбрал участие в одном окружном хакатоне, но...</td>\n",
       "      <td>Чтобы сменить хакатон, необходимо зайти в ЛК, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Я зарегистрировался, собрал команду. Что дальше?</td>\n",
       "      <td>Команда должна перейти в ЛК на сайте проекта в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Вопросы по кейсу и трекерам можно задавать тол...</td>\n",
       "      <td>Любые вопросы по кейсу правильнее всего задава...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Когда и как команда должна предоставить разраб...</td>\n",
       "      <td>Согласно расписанию хакатона, строго до дедлай...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Каковы требования к разработанному решению (пр...</td>\n",
       "      <td>Созданный Участником Прототип не должен содерж...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Как будет происходить презентация проектов?</td>\n",
       "      <td>Структуру и регламент презентации решения кейс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Будет ли проводиться ассессмент во время прове...</td>\n",
       "      <td>В этом году решено не проводить ассессмент уч...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Q  \\\n",
       "0   Как мне принять участие/подать заявку на участ...   \n",
       "1   Я принимал участие в Конкурсе в 2021, 2022 и/и...   \n",
       "2   Как я узнаю, что моя команда допущена к участи...   \n",
       "3   Я выбрал участие в одном окружном хакатоне, но...   \n",
       "4    Я зарегистрировался, собрал команду. Что дальше?   \n",
       "..                                                ...   \n",
       "66  Вопросы по кейсу и трекерам можно задавать тол...   \n",
       "67  Когда и как команда должна предоставить разраб...   \n",
       "68  Каковы требования к разработанному решению (пр...   \n",
       "69        Как будет происходить презентация проектов?   \n",
       "70  Будет ли проводиться ассессмент во время прове...   \n",
       "\n",
       "                                                    A  \n",
       "0   1. На сайте проекта https://hacks-ai.ru/ в тай...  \n",
       "1   Для того чтобы принять участие в хакатоне ново...  \n",
       "2   Участники команд получат письмо с подтверждени...  \n",
       "3   Чтобы сменить хакатон, необходимо зайти в ЛК, ...  \n",
       "4   Команда должна перейти в ЛК на сайте проекта в...  \n",
       "..                                                ...  \n",
       "66  Любые вопросы по кейсу правильнее всего задава...  \n",
       "67  Согласно расписанию хакатона, строго до дедлай...  \n",
       "68  Созданный Участником Прототип не должен содерж...  \n",
       "69  Структуру и регламент презентации решения кейс...  \n",
       "70   В этом году решено не проводить ассессмент уч...  \n",
       "\n",
       "[71 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"data.txt\")\n",
    "\n",
    "loader = DataFrameLoader(data, page_content_column='Q')         # зададим ключ для поиска по текстам, это колонка с вопросом\n",
    "documents = loader.load()                                       # обёртка над датафреймом, отсюда будем брать контекст\n",
    "\n",
    "data\n",
    "# loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/w/lab/py/my_venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/s/w/lab/py/my_venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9f867607454902902bd2b995e08eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  50%|#####     | 220M/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e390834cec8b49cb884c0988c7968cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4c4c43fa0242e783c1d636121b6f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bcc54c0d02a428293b93c40bf9804c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9527facf782343d59be918439d9a7951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd98b7207ca34732824208c17f8663c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# класс-обёртка для создания эмбеддингов текстов\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# сравнительно простая (и быстрая) модель, выдаёт эмбеддинги (векторы) для текстов\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings_maker = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    "    force_download=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# максимальная длина (в токенах) входной последовательности\n",
    "# токен - слово, часть слова или буква\n",
    "embeddings_maker.client.max_seq_length                  # 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# размерность эмбеддинга \n",
    "embeddings_maker.client.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нейросеть выдающая эмбеддинги текстов \n",
    "# embeddings_maker.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# объект, который будет разбивать тексты из датасета на блоки, если вдруг они будут слишком большими для модели выдающий эмбеддинги\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = embeddings_maker.client.max_seq_length, chunk_overlap=0)\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size = 50, chunk_overlap=0)        # для примера\n",
    "# chunk_size - это размер блока в токенах, будет разбивать на части только ключ (здесь, это вопрос)\n",
    "\n",
    "# получим блоки. Блок = (вопрос (ключ), ответ);\n",
    "# Вопрос может быть не полным, если не поместится в chunk_size. Тогда создаётся новый блок, с остатком вопроса, но с таким же ответом.\n",
    "texts = text_splitter.split_documents(documents)\n",
    "len(texts)          # при максимальном размере вопроса в токенах 384, разбивать вопросы на части не пришлось.\n",
    "# texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Мне нет 14 лет, но я хочу принять участие в хакатоне, есть ли такая возможность?', metadata={'A': 'В хакатоне может принять участие физическое лицо, достигшее 14 лет. Если в команде окажется участник младше 14 лет, к сожалению, вся команда будет дисквалифицирована вне зависимости от занятого ею места в хакатоне.'}),\n",
       "  0.23950584),\n",
       " (Document(page_content='Мне нет 14 лет, но я хочу принять участие в хакатоне, есть ли у меня такая возможность?', metadata={'A': 'В хакатоне может принять участие физическое лицо, достигшее 14 лет. Если в команде окажется участник младше 14 лет, к сожалению, вся команда будет дисквалифицирована вне зависимости от занятого ею места в хакатоне.  Как будут проходить окружные хакатоны'}),\n",
       "  0.24520686),\n",
       " (Document(page_content='Могу ли я участвовать в нескольких хакатонах?', metadata={'A': 'Согласно Положению о проекте вы имеете право участвовать в нескольких хакатонах. Однако в случае занятия 1, 2 или 3 места на одном из окружных хакатонов в 2024 году, вы не сможете принять участие в других окружных хакатонах. Тем не менее вы по-прежнему сможете испытать свои силы во всероссийском и международном хакатонах.'}),\n",
       "  0.36295044),\n",
       " (Document(page_content='Кто может принять участие в хакатоне?', metadata={'A': 'Гражданин Российской Федерации, достигший 14 лет и обладающий компетенциями в сфере разработки решений на основе технологий искусственного интеллекта.'}),\n",
       "  0.41715854),\n",
       " (Document(page_content='Мне исполняется 14 лет после начала регистрации. Могу ли я принять участие?', metadata={'A': 'К участию и к борьбе за денежный приз допускаются лица, которым исполнилось 14 лет строго на момент старта регистрации в конкретном выбранном им окружном хакатоне.'}),\n",
       "  0.42267123)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# класс для хранения данных как в векторной БД?. Используется для быстрого поиска подходящего контекста по запросу\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# создаем хранилище\n",
    "db = FAISS.from_documents(texts, embeddings_maker)\n",
    "db.as_retriever()           # ???ы\n",
    "\n",
    "# пример использования:\n",
    "db.similarity_search_with_score('Мне 10 лет. Я могу участвовать в хакатоне?', k = 5 )\n",
    "# поданный запрос переводится в эмбеддинг, для него выдаётся топ K самых похожих частей датасета (вопрос, ответ, расстояние)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Есть чат в телеграмме.**\n",
      "\n",
      "Канал телеграмме имеет название **\"Россия — страна возможностей\"**.\n",
      "\n",
      "**Адрес:** chat.russia.org\n",
      "\n",
      "**Способ доступа:**\n",
      "\n",
      "1. Зайдите в приложение Telegram.\n",
      "2. Введите название канала **\"Россия — страна возможностей\"**.\n",
      "3. Выберите свою учетную запись.\n",
      "4. Настройте чат.\n",
      "\n",
      "**Важно:**\n",
      "\n",
      "* Вам необходимо иметь активную учетную запись на платформе Telegram.\n",
      "* Для того, чтобы создать чат, вам необходимо быть по возрасту 18 лет."
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# request = 'Мне 10 лет. Я могу участвовать в хакатоне?'\n",
    "# request = 'Мне 100 лет. Я могу участвовать в хакатоне?'\n",
    "# request = 'Сколько участников должно быть в команде?'\n",
    "request = 'Есть ли чат в телеграмме? Если есть, то какой адрес?'\n",
    "\n",
    "context = db.similarity_search_with_score(request, k = 5 )\n",
    "context = \" \".join([text[0].metadata['A'] for text in context])\n",
    "context\n",
    "\n",
    "response = ollama.chat(model='gemma:2b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': f'Дай развёрнутый и как можно более точный ответ. Для ответа используй дополнительную информацию.\\nВопрос: {request}.\\n Дополнительная информация: {context}',}],\n",
    "    stream = True         # отвечать последовательно выдавая текст, а не отдельным готовым блоком текста\n",
    ")\n",
    "# print(response['message']['content'])\n",
    "\n",
    "for chunk in response:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
